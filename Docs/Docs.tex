
%%%%%%%%%%%%%%%%%%%%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input - copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\usepackage{url}
\urldef{\mailsa}\path|{alfred.hofmann, ursula.barth, ingrid.haas, frank.holzwarth,|
	\urldef{\mailsb}\path|anna.kramer, leonie.kunz, christine.reiss, nicole.sator,|
	\urldef{\mailsc}\path|erika.siebert-cole, peter.strasser, lncs}@springer.com|    
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
	\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}
	
	\mainmatter  % start of an individual contribution
	
	% first the title is needed
	\title{Mitigación de sesgos con ensembles y
		optimización multiobjetivo}
	
	% a short form should be given in case it is too long for the running head
	\titlerunning{SRI}
	
	% the name(s) of the author(s) follow(s) next
	%
	% NB: Chinese authors should write their first names(s) in front of
	% their surnames. This ensures that the names appear correctly in
	% the running heads and the author index.
	%
	\author{Rodrigo García, Jorge Mederos}
	%
	\authorrunning{IA}
	% (feature abused for this document to repeat the title also on left hand pages)
	
	% the affiliations are given next; don't give your e-mail address
	% unless you accept that it will be published
	\institute{MATCOM, Universidad de La Habana, Cuba\\
		\url{http:/matcom.uh.cu}}
	
	%
	% NB: a more complex sample for affiliations and the mapping to the
	% corresponding authors can be found in the file "llncs.dem"
	% (search for the string "\mainmatter" where a contribution starts).
	% "llncs.dem" accompanies the document class "llncs.cls".
	%
	
	\toctitle{Mitigación de sesgos con ensembles y
		optimización multiobjetivo}
	\tocauthor{Rodrigo García, Jorge Mederos}
	\maketitle
	
	
	
	
	\chapter*{Introducción}\label{chapter:introduction}
	\addcontentsline{toc}{chapter}{Introducción}
	
	Los algoritmos de aprendizaje automático han ido ganando  relevancia en los últimos años, hasta llegar a convertirse en una tecnología habitual al resolver tareas de la vida cotidiana. Tal es así, que muchas veces los algoritmos de aprendizajes automático pasan desapercibidos por los usuarios finales de los productos que usan la tecnología. Esto ha influido en el interés por parte de la comunidad científica en estudiar a fondo dichos algoritmos, sus ventajas y limitaciones. La popularidad y la influencia en la vida diaria humana han llevado a varias preocupaciones ¿Hasta que punto podemos confiar en las decisiones tomadas por una máquina entrenada por un algoritmo de aprendizaje automático? ¿Cómo podemos saber que las decisiones que toma esta máquina son justas? Se puede entender como justicia o equidad a la ausencia de favoritismo o prejuicios hacia un individuo o grupo, basado en características inherentes o adquiridas.\\
	Los algoritmos usan conjuntos de datos sacados de las sociedades humanas, por tanto, los sesgos existentes en estas pueden potencialmente verse reflejados en las decisiones tomadas por la máquina entrenada. Estos sesgos pueden, incluso, verse amplificados.\\
	Lo anterior deja ver la importancia que tiene para la sociedad el estudio de las formas de eliminación de los sesgos, ya sean, entre muchos otros, raciales o de género. La responsabilidad de esto cae en manos de los desarrolladores y el presente trabajo pretende dar ciertos aportes a la solución de dicho problema. Un ejemplo claro del riesgo de ignorar lo anterior es la popularización de representaciones semánticas pre-entrenadas en registros históricos, contenedores de sesgos sociales.\\
	En los últimos años ha crecido el interés por el desarrollo de técnicas que permitan identificar y eliminar los sesgos en algoritmos de aprendizaje automático, pero que mantengan al mismo tiempo la precisión de los modelos.\\	
	Una de las principales desventajas del Aprendizaje de Máquina es el nivel de preparación que tiene que
	tener un investigador o ingeniero para sacar provecho de las técnicas en problemas reales.
	Para ello se han venido explorando muy recientemente alternativas que permitan
	automatizar el proceso de selección y entrenamiento de modelos de aprendizaje de máquina,
	permitiendo a los ingenieros e investigadores enfocarse en los detalles que no pueden ser
	automatizados o son de dominio muy específico y así atacar los problemas de una forma más
	ágil. A este tipo de técnicas se les conoce como técnicas de AutoML y están jugando un
	papel fundamental en la democratización de la inteligencia artificial y el aprendizaje de
	máquinas.\\
	Finalmente, el objetivo fundamental de el presente trabajo es
	obtener un método basado en ensembles que permita construir modelos con alta precisión
	para problemas de clasificación. Poniendo énfasis en la explotación de la diversidad entre los
	integrantes de los ensembles y permitiendo la optimización de mas de una métrica, abriendo
	paso a aplicaciones como la mitigación de los sesgos antes mencionados.\\
	Para lograr el objetivo planteado, luego de una amplia curva de investigación y aprendizaje, se llegó a una solución que hace uso de algoritmos como Non-dominated Sorting y Probabilistic Grammatical Evolution.
	
	\section*{Motivación}
	
	Un modelo de aprendizaje de maquina se entrena con el objetivo de optimizar una unica metrica, en la mayoria de los casos la precision. Esto significa que los modelos aprenden muy bien los patrones que se presentan en los datos de entrenamiento, incluyendo aquellos patrones que representan sesgos y prejuicios que estan desafortunadamente presente en la sociedad y por ende en los datos recopilados, en algunos casos incluso amplifican estos patrones negativos. Son varias la tecnicas que se han explorado para resolver este problema, algunas se enfocan en un preprocesamiento de los datos para eliminar aquellos elementos que puedan inducir un sesgo en el modelo, otras realizan variacinoes en el metodo de entrenamiento con el mismo objetivo. Sin embargo permanece relativamente poco explorado el uso de tecnicas de optimizacion multiobjetivo que permitan al modelo optimizar hasta encontrar un buen balance entre cuan justo es y cuan preciso.
	
	Otra tecnica que ha demostrado ser de gran utilidad en la prevencion de los sesgos en los modelos de aprendizaje de maquina es la construccion de ensamblados de multiples modelos que maximizan la varianza entre si, por lo que se minimiza el sesgo del ensamblado final.
	
	\section*{Problematica}
	
	Las propuestas actuales para medir y mitigar sesgos en busca de justicia, presentan varias limitaciones desde el punto de vista de aplicación a problemas arbitrarios. En específico, existen pocas propuestas que generen una solución end-to-end a problemas arbitrarios, y las que existen trabajan con una colección limitada de técnicas de mitigación o son aplicables a dominios limitados. El enfoque basado en ensemble de nuestra propuesta trae algunas ventajas adicionales.\\
	En particular, permanecen poco explorados los enfoques multi-objetivo para la obtención de modelos justos y precisos.
	
	\section*{Objetivo general}
	
	Proponer una herramienta que permita resolver problemas de clasificacion utilizando aprendizaje de maquina y que permita garantizar que el modelo aprendido sea justo.
	
	\section*{Objetivos especificos}
	
	\begin{itemize}
		\item Encontrar modelos que maximicen la varianza para minimizar el sesgo.
		\item Metodos basados en metaheuristicas para optimizar los modelos utilizando simultaneamente metricas de equidad y precision.
		\item Explorar adicion de optimizacion multiobjetivo a AutoGOAL para que el modelo aprendido sea justo.
		\item Metodos basados en la combinacion de diferentes metricas en una sola, para poder aprovechar los multiples metodos de optimizacion que existen.
	\end{itemize}
	
	\section*{Propuesta}\label{chapter:proposal}
	
	El método empleado consiste en dos fases. Una primera fase en la que se buscan los modelos que
	maximizan una métrica de diversidad mientras que se optimiza la precisión de los mismos. Luego una
	segunda fase utiliza los \emph{n} modelos anteriormente obtenidos para ser ensamblados utilizando un
	enfoque multiobjetivo donde se optimizan simultaneamente una metrica de equidad y la precision.
	
	\subsection*{Generación de modelos con diversidad alta para una tarea determinada}
	
	Para esta fase utilizamos una tecnica que puede pensarse como una generalización basada en AutoML de
	la idea presentada en [2]. En particular se utiliza una modificacion de
	Probabilistic Gramatical Evolution Search que permite controlar características de la población como
	por ejemplo en este caso mantener en todo momento las n soluciones mas diversas que se han explorado
	durante el proceso de busqueda. Esto se logra manteniendo en cada generacion del algoritmo los n mejores
	modelos en cuanto a una funcion de ranking.
	
	La función de ranking que se utiliza para ordernar las soluciones de acorde a su diversidad. En este
	momento utiliza un enfoque greedy, en el cual se comienza ordenando las soluciones según la precisión
	en un conjunto de evaluación, y luego se procede a asignarle un rank a cada clasificador en funcion
	de la diversidad que presenta este con el conjunto de soluciones seleccionadas hasta el momento,
	priorizando a los clasificadores con mayor precisión y añadiendo al final de este proceso el
	clasificador mejor rankeado al conjunto de soluciones seleccionadas, este proceso se repite hasta
	que todos los clasificadores son asignados un rank.
	
	Para computar la diversidad relativa entre un par de clasificadores se utiliza una de las metricas
	de diversidad descritas en [1], ajustada de forma que refleje la diversidad
	relativa entre pares de clasificadores en vez de la diversidad de todo el conjunto.
	
	\subsection*{Ensamblado de los modelos utilizando multiples criterios}

    Existen diferentes metodos en la literatura para resolver el problema de optimizacion multiobjetivo,
    en particular en este caso la funcion a optimizar es una funcion extremadamente costosa de evaluar,
    dado que cada punto en nuestro espacio de busqueda es un modelo, el cual debemos entrenar y evaluar
    en el dataset para poder obtener su evaluacion en las metricas. Existe metodos de muy buena calidad
    que cumple con esta restriccion, vease [3]. Sin embargo estos metodos asumen en muchas ocasiones
    características del dominio de las funciones que se estan optimizando, como por ejemplo asumen
    continuidad o estar en R\^n. Nuestro espacio sin embargo no tiene ninguna de estas caracteristicas,
    nuestro espacio consiste de vectores que codifican las decisiones y parametros que definen un metodo de
    ensemble, es muy dificil intentar codificar este espacio en algo similar a los naturales o los reales
    sin tener problemas de dimensionalidad.
	
	Por lo explicado anteriormente, para la construcción del ensemble a partir de los modelos obtenidos
    en la primera fase se utiliza un hibrido entre Probabilistic Gramatical Evolution y NSGA-II. En
    particular tomamos los metodos de Non-dominated Sorting y Crowding Distance de NSGA-II y los
    incorporamos a Probabilistic Gramatical Evolution, en particular al paso de decidir los individuos
    que pasan a la siguiente generacion.
	
	Non-dominated Sorting consiste en ordenar los individuos de forma tal que sean priorizados aquellos
	individuos que sean dominados por la menor cantidad de individuos de la población. Donde un individuo
	domina a otro si este mejora al menos una de las metricas a optimizar, sin comprometer ninguna de las
	otras.
	
	\section*{Conclusiones}
	Con las pruebas realizadas queda claro luego de la segunda fase de procesamiento se obtienen soluciones más justas que las obtenidas inicialmente. Esto es de esperarse pues la naturaleza de Probabilistic Grammatical Evolution y Non-dominated Sorting, provee la capacidad de medir y, cada vez generar soluciones más parecidas a las soluciones pareto eficientes del problema.\\
	Este método desarrollado se ha beneficiado con el hecho de que en la segunda fase se trabaja sobre modelos que ya han sido optimizados durante la primera y, por tanto, son buenos en al menos una de las métricas que se quieren optimizar en la segunda (En este caso la precisión).\\
	A partir de este punto, es necesario evaluar extensivamente el enfoque propuesto para la segunda fase y compararlo con las alternativas previamente existentes. Además, se debe investigar cómo explorar una solución diferente a Probabilistic Grammatical Evolution, y lograr analizar así si existe una manera más eficaz de calcular los individuos que serán añadido a la población en la próxima generación. En esto deben enfocarse los estudios futuros.
	
	
	\begin{thebibliography}{4}
		
		\bibitem{1} Tang, E. K. and Suganthan, P. N. and Yao, X. An analysis of diversity measures. Machine Learning. 2006.
		\bibitem{2} Gao Huang and Yixuan Li and Geoff Pleiss and Zhuang Liu and John E. Hopcroft and Kilian Q. Weinberger. Snapshot Ensembles: Train 1, get {M} for free. CoRR. 2017,
        \bibitem{3} Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa. Max-value Entropy Search for Multi-Objective Bayesian Optimization.
		
	\end{thebibliography}
	
	
\end{document}
